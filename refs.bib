% === BOOKS ===

@book{tieste_keine_2015,
    address = {Wiesbaden},
    edition = {3},
    title = {Keine {Panik} vor {Regelungstechnik}! {Erfolg} und {Spaß} im {Mystery}-{Fach} des {Ingenieurstudiums}},
    isbn = {978-3-658-08535-3},
    publisher = {Springer Vieweg},
    author = {Tieste, Karl-Dieter and Romberg, Oliver},
    year = {2015},
}

@book{zacher_regelungstechnik_2022,
    address = {Wiesbaden},
    title = {Regelungstechnik für {Ingenieure}: {Analyse}, {Simulation} und {Entwurf} von {Regelkreisen}},
    isbn = {978-3-658-37666-6},
    publisher = {Springer Vieweg},
    author = {Zacher, Serge and Reuter, Manfred},
    year = {2022},
}

@book{follinger_regelungstechnik_2022,
    address = {Berlin},
    edition = {13},
    title = {Regelungstechnik: {Einführung} in die {Methoden} und ihre {Anwendung}},
    isbn = {978-3-8007-5517-2},
    publisher = {VDE Verlag},
    author = {Föllinger, Otto and Konigorski, Ulrich and Lohmann, Boris},
    year = {2022},
}

@book{schroder_elektrische_2015,
    address = {Berlin, Heidelberg},
    title = {Elektrische {Antriebe} - {Regelung} von {Antriebssystemen}},
    isbn = {978-3-642-30095-0},
    publisher = {Springer},
    author = {Schröder, Dierk},
    year = {2015},
}

% === THESES (PhD / Master) ===

@phdthesis{gemasmer_effiziente_2015,
    type = {Dissertation},
    title = {Effiziente und dynamische {Drehmomenteinprägung} in hoch ausgenutzten {Synchronmaschinen} mit eingebetteten {Magneten}},
    school = {Karlsruher Institut für Technologie (KIT)},
    author = {Gemaßmer, Tobias},
    year = {2015},
    doi = {10.5445/KSP/1000046666},
}

@mastersthesis{kellner_parameter_2012,
    title = {Parameter {Identification} of {Permanent} {Magnet} {Synchronous} {Machines}},
    school = {Friedrich-Alexander-Universität Erlangen-Nürnberg},
    author = {Kellner, Sven Ludwig},
    year = {2012},
}

@phdthesis{ackermann_optimale_2012,
    type = {Dissertation},
    title = {Optimale {Regelung} der permanentmagneterregten {Synchronmaschine} unter {Nutzung} des {Reluktanzmoments}},
    school = {Karlsruher Institut für Technologie (KIT)},
    author = {Ackermann, Carsten},
    year = {2012},
    doi = {10.5445/IR/1000041168},
}

@mastersthesis{tasnim_mitigating_2024,
    title = {Mitigating delay and coupling effects in a high-speed {PMSM} drive using an optimal multivariable control approach},
    school = {Mississippi State University},
    author = {Tasnim, Kazi Nishat},
    year = {2024},
}

@phdthesis{coluccio_exploration_2023,
    address = {Turin, Italy},
    title = {Exploration of {Beyond} von {Neumann} {Computing} to solve the {Memory}-{Wall} issue},
    school = {Politecnico di Torino},
    author = {Coluccio, Andrea},
    year = {2023},
}

% === ARTICLES & JOURNALS ===

@article{balakrishna_gym-electric-motor_2021,
    title = {gym-electric-motor ({GEM}): {A} {Python} toolbox for the simulation of electric drive systems},
    volume = {6},
    journal = {Journal of Open Source Software (JOSS)},
    author = {Balakrishna, Praneeth and Book, Gerrit and Kirchgässner, Wilhelm and Schenke, Maximilian and Traue, Arne and Wallscheid, Oliver},
    year = {2021},
    pages = {2498},
    doi = {10.21105/joss.02498},
}

@article{yik_neurobench_2025,
    title = {The {NeuroBench} framework for benchmarking neuromorphic computing algorithms and systems},
    volume = {16},
    number = {1},
    journal = {Nature Communications},
    author = {Yik, Jason and Van den Berghe, Korneel and den Blanken, Douwe and others},
    year = {2025},
    pages = {1545},
    doi = {10.1038/s41467-025-56739-4},
}

@article{pedersen_neuromorphic_2024,
    title = {Neuromorphic intermediate representation: {A} unified instruction set for interoperable brain-inspired computing},
    volume = {15},
    number = {1},
    journal = {Nature Communications},
    author = {Pedersen, Jens E. and Abreu, Steven and Jobst, Matthias and others},
    year = {2024},
    pages = {8122},
    doi = {10.1038/s41467-024-52259-9},
}

@article{hueber_benchmarking_2024,
    title = {Benchmarking of hardware-efficient real-time neural decoding in brain–computer interfaces},
    volume = {4},
    number = {2},
    journal = {Neuromorphic Computing and Engineering},
    author = {Hueber, Paul and Tang, Guangzhi and Sifalakis, Manolis and others},
    year = {2024},
    pages = {024008},
    doi = {10.1088/2634-4386/ad4411},
}

@article{dewolf_spiking_2016,
    title = {A spiking neural model of adaptive arm control},
    volume = {283},
    number = {1843},
    journal = {Proceedings of the Royal Society B: Biological Sciences},
    author = {DeWolf, Travis and Stewart, Terrence C. and Slotine, Jean-Jacques and Eliasmith, Chris},
    year = {2016},
    pages = {20162134},
    doi = {10.1098/rspb.2016.2134},
}

@article{stewart_closed-loop_2015,
    title = {Closed-{Loop} {Neuromorphic} {Benchmarks}},
    volume = {9},
    journal = {Frontiers in Neuroscience},
    author = {Stewart, Terrence C. and DeWolf, Travis and Kleinhans, Ashley and Eliasmith, Chris},
    year = {2015},
    doi = {10.3389/fnins.2015.00464},
}

@article{li_current_2024,
    title = {Current decoupling control of permanent magnet synchronous motor based on improved nonlinear extended state observer},
    volume = {30},
    number = {23-24},
    journal = {Journal of Vibration and Control},
    author = {Li, Shuai and Wang, Hai and Yang, Chunlai and Li, Henian and Gui, Jinsong and Fu, Ronghua},
    year = {2024},
    pages = {5401--5417},
    doi = {10.1177/10775463231222780},
}

@article{kulkarni_benchmarking_2021,
    title = {Benchmarking the performance of neuromorphic and spiking neural network simulators},
    volume = {447},
    journal = {Neurocomputing},
    author = {Kulkarni, Shruti R. and Parsa, Maryam and Mitchell, J. Parker and Schuman, Catherine D.},
    year = {2021},
    pages = {145--160},
    doi = {10.1016/j.neucom.2021.03.028},
}

@article{cramer_heidelberg_2022,
    title = {The {Heidelberg} spiking datasets for the systematic evaluation of spiking neural networks},
    volume = {33},
    number = {7},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    author = {Cramer, Benjamin and Stradmann, Yannik and Schemmel, Johannes and Zenke, Friedemann},
    year = {2022},
    pages = {2744--2757},
    doi = {10.1109/TNNLS.2020.3044364},
}

@article{schuman_opportunities_2022,
    title = {Opportunities for neuromorphic computing algorithms and applications},
    volume = {2},
    number = {1},
    journal = {Nature Computational Science},
    author = {Schuman, Catherine D. and Kulkarni, Shruti R. and Parsa, Maryam and others},
    year = {2022},
    pages = {10--19},
    doi = {10.1038/s43588-021-00184-y},
}

@article{steffen_benchmarking_2021,
    title = {Benchmarking {Highly} {Parallel} {Hardware} for {Spiking} {Neural} {Networks} in {Robotics}},
    volume = {15},
    journal = {Frontiers in Neuroscience},
    author = {Steffen, Lea and Koch, Robin and Ulbrich, Stefan and others},
    year = {2021},
    doi = {10.3389/fnins.2021.667011},
}

@article{milde_neuromorphic_2022,
    title = {Neuromorphic {Engineering} {Needs} {Closed}-{Loop} {Benchmarks}},
    volume = {16},
    journal = {Frontiers in Neuroscience},
    author = {Milde, Moritz B. and Afshar, Saeed and Xu, Ying and others},
    year = {2022},
    doi = {10.3389/fnins.2022.813555},
}

@article{lin_energy_2025,
    title = {The {Energy} {Paradox} of {AI} in {Power} {Electronics}: {Innovation} {Driver} or {Unsustainable} {Burden}?},
    volume = {12},
    number = {4},
    journal = {IEEE Power Electronics Magazine},
    author = {Lin, Fanfan and Novak, Mateja and Sahoo, Subham and Wilson, Peter},
    year = {2025},
    pages = {44--56},
    doi = {10.1109/MPEL.2025.3624980},
}

@article{chowdhury_neuromorphic_2025,
    title = {Neuromorphic computing for robotic vision: algorithms to hardware advances},
    volume = {4},
    journal = {Communications Engineering},
    author = {Chowdhury, Sayeed Shafayet and Sharma, Deepika and Kosta, Adarsh and Roy, Kaushik},
    year = {2025},
    pages = {152},
    doi = {10.1038/s44172-025-00492-5},
}

@article{diamond_comparing_2016,
    title = {Comparing {Neuromorphic} {Solutions} in {Action}: {Implementing} a {Bio}-{Inspired} {Solution} to a {Benchmark} {Classification} {Task} on {Three} {Parallel}-{Computing} {Platforms}},
    volume = {9},
    journal = {Frontiers in Neuroscience},
    author = {Diamond, Alan and Nowotny, Thomas and Schmuker, Michael},
    year = {2016},
    doi = {10.3389/fnins.2015.00491},
}

% === CONFERENCE PROCEEDINGS ===

@inproceedings{mitchell_neon_2017,
    title = {{NeoN}: {Neuromorphic} control for autonomous robotic navigation},
    booktitle = {2017 {IEEE} {International} {Symposium} on {Robotics} and {Intelligent} {Sensors} ({IRIS})},
    author = {Mitchell, J. Parker and Bruer, Grant and Dean, Mark E. and Plank, James S. and Rose, Garrett S. and Schuman, Catherine D.},
    year = {2017},
    pages = {136--142},
    doi = {10.1109/IRIS.2017.8250111},
}

@inproceedings{kumarasinghe_faneurobot_2018,
    title = {{FaNeuRobot}: {A} {Framework} for {Robot} and {Prosthetics} {Control} {Using} the {NeuCube} {Spiking} {Neural} {Network} {Architecture} and {Finite} {Automata} {Theory}},
    booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
    author = {Kumarasinghe, Kaushalya and Owen, Mahonri and Taylor, Denise and Kasabov, Nikola and Kit, Chi},
    year = {2018},
    pages = {4465--4472},
    doi = {10.1109/ICRA.2018.8460197},
}

@inproceedings{plank_tennlab_2019,
    title = {The {TENNLab} {Suite} of {LIDAR}-{Based} {Control} {Applications} for {Recurrent}, {Spiking}, {Neuromorphic} {Systems}},
    booktitle = {44th {Annual} {GOMACTech} {Conference}},
    address = {Albuquerque, New Mexico},
    author = {Plank, James S. and Rizzo, Charles and Shahat, Kirolos and others},
    year = {2019},
}

@inproceedings{polykretis_astrocyte-modulated_2020,
    title = {An {Astrocyte}-{Modulated} {Neuromorphic} {Central} {Pattern} {Generator} for {Hexapod} {Robot} {Locomotion} on {Intel}’s {Loihi}},
    booktitle = {International {Conference} on {Neuromorphic} {Systems} ({ICONS} 2020)},
    publisher = {ACM},
    author = {Polykretis, Ioannis and Tang, Guangzhi and Michmizos, Konstantinos P.},
    year = {2020},
    pages = {1--9},
    doi = {10.1145/3407197.3407205},
}

@inproceedings{amaya_neuromorphic_2024,
    title = {Neuromorphic force-control in an industrial task: validating energy and latency benefits},
    booktitle = {2024 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
    author = {Amaya, Camilo and Eames, Evan and Palinauskas, Gintautas and others},
    year = {2024},
    pages = {717--724},
    doi = {10.1109/IROS58592.2024.10802430},
}

% === MISC / REPORTS (The "No Author" Fixes) ===

@misc{abb_achieving_2023,
    title = {Achieving the {COP28} {UAE} consensus - {The} vital role of high efficiency motors and drives in net energy addition and lower emissions globally},
    author = {{ABB Motion}},
    year = {2023},
    url = {https://search.abb.com/library/Download.aspx?DocumentID=9AKK108471A1666},
    note = {Whitepaper},
}

@misc{edgeimpulse_revolutionizing_2024,
    title = {Revolutionizing {Smart} {Manufacturing} with {Edge} {AI}},
    author = {{Edge Impulse}},
    year = {2024},
    month = may,
    url = {https://www.edgeimpulse.com/blog/revolutionizing-smart-manufacturing-with/},
    note = {Blog Post},
}

@misc{factmr_neuromorphic_2025,
    title = {Neuromorphic {Hardware} {Market} {Insights} 2025 to 2035},
    author = {{Fact.MR}},
    year = {2025},
    url = {https://www.factmr.com/report/neuromorphic-hardware-market},
    note = {Market Research Report},
}

@misc{ramamoorthy_fcls_2022,
    title = {{FCLs} for {Servo} {Drives}},
    author = {Ramamoorthy, Ramesh T.},
    year = {2022},
    journal = {Circuit Cellar},
    url = {https://circuitcellar.com/research-design-hub/design-solutions/fcls-for-servo-drives/},
}

@misc{eshraghian_training_2023,
    title = {Training {Spiking} {Neural} {Networks} {Using} {Lessons} {From} {Deep} {Learning}},
    author = {Eshraghian, Jason K. and Ward, Max and Neftci, Emre and others},
    year = {2023},
    eprint = {2109.12894},
    archivePrefix = {arXiv},
    primaryClass = {cs.NE},
    note = {arXiv preprint},
}
@article{hevner2004design,
  author    = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
  title     = {Design Science in Information Systems Research},
  journal   = {MIS Quarterly},
  volume    = {28},
  number    = {1},
  pages     = {75--105},
  year      = {2004},
  publisher = {Society for Information Management and The Management Information Systems Research Center},
  doi       = {10.2307/25148625}
}

@article{jr_spiking_2025,
	title = {Spiking {Neural} {Networks}: {The} {Future} of {Brain}-{Inspired} {Computing}},
	volume = {73},
	issn = {2231-5381},
	shorttitle = {Spiking {Neural} {Networks}},
	url = {https://ijettjournal.org/archive/ijett-v73i10p104},
	doi = {10.14445/22315381/IJETT-V73I10P104},
	abstract = {Spiking Neural Networks (SNNs) represent the latest generation of neural computation, offering a brain-inspired alternative to conventional Artificial Neural Networks (ANNs). Unlike ANNs, which depend on continuous-valued signals, SNNs operate using distinct spike events, making them inherently more energy-efficient and temporally dynamic. This study presents a comprehensive analysis of SNN design models, training algorithms, and multi-dimensional performance metrics, including accuracy, energy consumption, latency, spike count, and convergence behavior. Key neuron models such as the Leaky Integrate-and-Fire (LIF) and training strategies—including surrogate gradient descent, ANN-to-SNN conversion, and Spike-Timing Dependent Plasticity (STDP)—are examined in depth. Results show that surrogate gradient-trained SNNs closely approximate ANN accuracy (within 1–2\%), with faster convergence by the 20th epoch and latency as low as 10 milliseconds. Converted SNNs also achieve competitive performance but require higher spike counts and longer simulation windows. STDP-based SNNs, though slower to converge, exhibit the lowest spike counts and energy consumption (as low as 5 millijoules per inference), making them optimal for unsupervised and low-power tasks. These findings reinforce the suitability of SNNs for energy-constrained, latency-sensitive, and adaptive applications such as robotics, neuromorphic vision, and edge AI systems. While promising, challenges persist in hardware standardization and scalable training. This study concludes that SNNs, with further refinement, are poised to propel the next phase of neuromorphic computing.},
	language = {English},
	urldate = {2026-01-10},
	journal = {International Journal of Engineering Trends and Technology - IJETT},
	author = {Jr, Sales G. Aribe},
	year = {2025},
	note = {Publisher: Seventh Sense Research Group®},
	file = {Full Text PDF:files/244/Jr - 2025 - Spiking Neural Networks The Future of Brain-Inspired Computing.pdf:application/pdf},
}

@book{boldea_electric_2017,
	edition = {3rd},
	title = {Electric {Drives}},
	isbn = {978-1-4987-4820-9},
	publisher = {CRC Press},
	author = {Boldea, Ion and Nasar, Syed A.},
	year = {2017},
}
