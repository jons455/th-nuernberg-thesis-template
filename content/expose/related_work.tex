\section{State of the Art}

\subsection{The Paradigm Shift: From Static Classification to Temporal Dynamics}
The stagnation of Moore's Law and the rising energy demands of edge computing have necessitated a paradigm shift toward brain-inspired computing architectures. While early adoption of Spiking Neural Networks (SNNs) was hindered by training difficulties, recent advances in surrogate gradient methods have allowed SNNs to achieve accuracy parity with traditional Artificial Neural Networks (ANNs) in static tasks, such as reaching 98\% on MNIST \cite{jr_spiking_2025, eshraghian_training_2023}. However, the true potential of SNNs lies not in static image classification, but in processing continuous, temporal data streams. Unlike ANNs, which rely on synchronous, dense matrix multiplications, SNNs exploit ``compute-on-demand'' sparsity, consuming energy only when significant events occur. This temporal characteristic offers theoretical energy reductions of up to 97\% \cite{aribe_spiking_2025} and makes them uniquely suited for cyber-physical systems where data is inherently asynchronous and causal \cite{schuman_opportunities_2022}.

\subsection{Neuromorphic Control Applications}
Leveraging these temporal advantages, recent research has begun to apply neuromorphic principles to robotics and control, though often in isolated or task-specific contexts. Early implementations, such as the \textit{NeoN} framework \cite{mitchell_neon_2017}, utilized Dynamic Adaptive Neural Network Arrays (DANNA) on FPGAs to enable autonomous robotic navigation. Similarly, the \textit{FaNeuRobot} framework by Kumarasinghe et al. \cite{kumarasinghe_faneurobot_2018} combined finite automata with evolving SNNs to decode electromyography (EMG) signals for prosthetic control.

More biologically plausible approaches have also been explored; Polykretis et al. \cite{polykretis_astrocyte-modulated_2020} demonstrated an astrocyte-modulated Central Pattern Generator (CPG) on the Intel Loihi chip, capable of generating stable locomotion gaits for a hexapod robot with $23 \times$ greater efficiency than reinforcement learning baselines. Most recently, Amaya et al. \cite{amaya_neuromorphic_2024} provided a significant proof-of-concept by implementing force-torque control for a KUKA robotic arm on Loihi, demonstrating that neuromorphic hardware can satisfy industrial latency requirements in a ``peg-in-hole'' insertion task. However, these contributions remain ``point solutions''---custom-built architectures optimized for a single robot or task, lacking a unified framework for comparative evaluation against classical control standards.

\subsection{The Deficit in Standardized Benchmarking}
Despite these individual successes, the field suffers from a lack of standardized benchmarking tools specifically designed for closed-loop control. The primary existing framework, \textit{NeuroBench} \cite{yik_neurobench_2025}, focuses heavily on open-loop perception tasks (e.g., speech and image recognition) or data-driven prediction, neglecting the strict stability requirements of feedback control systems. Milde et al. \cite{milde_neuromorphic_2022} explicitly argue that this focus on ``sensing accuracy'' is a proxy that fails to capture the system's ability to make timely decisions in a dynamic environment.

Existing efforts to benchmark robotics often miss the low-level control layer. For instance, Steffen et al. \cite{steffen_benchmarking_2021} benchmarked highly parallel hardware (SpiNNaker, GeNN) for robotics, but focused on the \textit{Wavefront algorithm} for path planning rather than high-speed motor actuation loops. Similarly, while the \textit{Heidelberg Spiking Datasets} \cite{cramer_heidelberg_2022} provide high-quality benchmarks for spike-based audio, they offer no equivalent for the continuous state-action spaces found in electric drives. Consequently, there is no established methodology to quantify how platform variability---a known issue where results differ significantly between simulators and hardware \cite{diamond_comparing_2016}---affects control quality (\textit{Regelg√ºte}).

\subsection{Methodological Gap: The Need for an Interface Layer}
This survey reveals a critical methodological gap: while we possess capable neuromorphic hardware and high-fidelity physical simulators for electric drives (e.g., \textit{gym-electric-motor}), there is no ``Interface Layer'' to couple them for standardized evaluation. Brain-Computer Interface (BCI) research has already demonstrated that SNNs can achieve sub-10~ms latency for neural decoding \cite{hueber_benchmarking_2024}, and adaptive arm controllers have shown biological plausibility \cite{dewolf_spiking_2016}. Yet, for the specific domain of high-dynamic PMSM control---where 20~kHz sampling rates create a ``Latency Wall''---a validated pipeline to benchmark SNNs against classical PI/MPC controllers is non-existent. This thesis addresses this deficit.